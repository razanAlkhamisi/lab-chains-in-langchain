{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ff7a628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (1.1.0)\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.23 (from langchain_community)\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain_community)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\http\\client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\ssl.py\", line 1307, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\ssl.py\", line 1163, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 237, in _attempt_to_pin_criterion\n",
      "    for candidate in criterion.candidates:\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 162, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 53, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 187, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 233, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 159, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 236, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 315, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 521, in prepare_linked_requirement\n",
      "    metadata_dist = self._fetch_metadata_only(req)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 373, in _fetch_metadata_only\n",
      "    return self._fetch_metadata_using_link_data_attr(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 393, in _fetch_metadata_using_link_data_attr\n",
      "    metadata_file = get_http_url(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 111, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 148, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\razan\\anaconda3\\envs\\SDA\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain) (0.3.51)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 799.2 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.1 MB 799.2 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 713.3 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 713.3 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 699.0 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 699.0 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 657.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 657.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 657.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 657.8 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 559.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 625.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 625.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 618.9 kB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Installing collected packages: greenlet, async-timeout, SQLAlchemy, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "Successfully installed SQLAlchemy-2.0.40 async-timeout-4.0.3 greenlet-3.1.1 langchain-0.3.23 langchain-text-splitters-0.3.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b4a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain-openai)\n",
      "  Using cached langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n",
      "  Downloading openai-1.74.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading langsmith-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.12.2)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading orjson-3.10.16-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\razan\\anaconda3\\envs\\sda\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
      "Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
      "Downloading openai-1.74.0-py3-none-any.whl (644 kB)\n",
      "   ---------------------------------------- 0.0/644.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 644.8/644.8 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/894.0 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/894.0 kB ? eta -:--:--\n",
      "   ---------------------- --------------- 524.3/894.0 kB 670.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 786.4/894.0 kB 670.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 894.0/894.0 kB 652.1 kB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-win_amd64.whl (208 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.3.31-py3-none-any.whl (358 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 381.0 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 381.0 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 381.0 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 381.0 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 345.8 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 1.3/2.0 MB 554.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 554.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.6/2.0 MB 578.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 662.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 651.6 kB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.16-cp310-cp310-win_amd64.whl (133 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, sniffio, PyYAML, pydantic-core, orjson, jsonpointer, jiter, h11, distro, annotated-types, tiktoken, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, httpx, openai, langsmith, langchain-core, langchain-openai\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.51 langchain-openai-0.3.12 langsmith-0.3.31 openai-1.74.0 orjson-3.10.16 pydantic-2.11.3 pydantic-core-2.33.1 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 typing-inspection-0.4.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Write a query that would take a variable to describe any product\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"You are a professional copywriter. Write a short, engaging, \"\n",
    "\"and persuasive product description for the following item:\\n\\nProduct: {product_name}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product Description Response:\n",
      " Upgrade your sleep experience with our luxurious pillow inserts. Filled with premium materials, these inserts provide the perfect balance of support and comfort for a restful night's sleep. Say goodbye to flat, lumpy pillows and hello to plush, fluffy goodness. Treat yourself to the ultimate relaxation with our high-quality pillow inserts. Your bed will thank you.\n"
     ]
    }
   ],
   "source": [
    "product = 'Pillows Insert' #Select a product type to be describe\n",
    "response=chain.run(product)\n",
    "\n",
    "\n",
    "print(\"\\nProduct Description Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "#Repeat the initial query or create a new query that would feed into the second prompt\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template( \n",
    "      \"You are a helpful assistant. Given the product name '{product_name}', write a brief, \" \\\n",
    "      \"engaging description of the product.\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "#Write the second prompt query that takes an input variable whose input will come from the previous prompt\"\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a professional marketer. Based on the product description below, write a short,\" \\\n",
    "    \" engaging promotional paragraph that would appeal to online shoppers.\\n\\nProduct Description: {description}\"\n",
    "\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mUpgrade your sleeping experience with our plush Pillows Insert. Made from premium materials, these inserts provide extra support and comfort for a restful night's sleep. Say goodbye to flat, lifeless pillows and hello to luxurious relaxation. Treat yourself to the ultimate in comfort with our Pillows Insert.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mAre you tired of tossing and turning on flat, lifeless pillows? Upgrade your sleep experience with our plush Pillows Insert! Made from premium materials, these inserts provide extra support and comfort for a restful night's sleep. Say goodbye to discomfort and hello to luxurious relaxation. Treat yourself to the ultimate in comfort and transform your bed into a cozy oasis. Sweet dreams await with our Pillows Insert!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Product Description Response:\n",
      " Are you tired of tossing and turning on flat, lifeless pillows? Upgrade your sleep experience with our plush Pillows Insert! Made from premium materials, these inserts provide extra support and comfort for a restful night's sleep. Say goodbye to discomfort and hello to luxurious relaxation. Treat yourself to the ultimate in comfort and transform your bed into a cozy oasis. Sweet dreams await with our Pillows Insert!\n"
     ]
    }
   ],
   "source": [
    "response2=overall_simple_chain.run(product)\n",
    "\n",
    "print(\"\\nProduct Description Response:\\n\", response2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  #This prompt should translate a review\n",
    "    \"Translate the following product review into French:\\n\\nReview: {review}\"\n",
    "\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"translated_review\" #Give a name to your output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    #Write a promplt to summarize a review\n",
    "        \"Summarize the following product review in a short and clear sentence:\\n\\nReview: {translated_review}\"\n",
    "\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key='summary' #give a name to this output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review written in?\\n\\n{review}\"\n",
    ")\n",
    "\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow-up message to the customer based on the review summary and original language.\\n\\n\"\n",
    "    \"Summary: {summary}\\n\"\n",
    "    \"Language: {language}\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"follow_up_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dd8f437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the input variables match the expected ones for each chain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],  # Include 'language' if it's needed\n",
    "    output_variables=[\"translated_review\", \"summary\",\"language\", \"follow_up_message\"],  # Include all required output variables\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Translated Review ---\n",
      " Avis : I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\n",
      "\n",
      "--- Summary ---\n",
      " The reviewer finds the taste of the product mediocre and the foam does not hold well, comparing it unfavorably to similar products purchased in stores.\n",
      "\n",
      "--- Language Detected ---\n",
      " French\n",
      "\n",
      "--- Follow-up Message ---\n",
      " Cher client,\n",
      "\n",
      "Nous avons bien reÃ§u votre avis concernant notre produit et nous sommes dÃ©solÃ©s d'apprendre que vous avez trouvÃ© le goÃ»t moyen et que la mousse ne tient pas bien. Nous prenons vos commentaires trÃ¨s au sÃ©rieux et nous souhaitons nous amÃ©liorer.\n",
      "\n",
      "Nous aimerions vous offrir un bon de rÃ©duction pour essayer un autre produit de notre gamme, dans l'espoir que vous puissiez trouver quelque chose qui correspond mieux Ã  vos attentes.\n",
      "\n",
      "N'hÃ©sitez pas Ã  nous contacter si vous avez des questions ou des prÃ©occupations supplÃ©mentaires. Merci pour votre retour d'expÃ©rience et votre soutien.\n",
      "\n",
      "Bien cordialement, \n",
      "\n",
      "L'Ã©quipe du service client\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review = df.Review[5]\n",
    "result = overall_chain({\"review\": review})\n",
    "\n",
    "print(\"\\n--- Translated Review ---\\n\", result[\"translated_review\"])\n",
    "print(\"\\n--- Summary ---\\n\", result[\"summary\"])\n",
    "print(\"\\n--- Language Detected ---\\n\", result[\"language\"])\n",
    "print(\"\\n--- Follow-up Message ---\\n\", result[\"follow_up_message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "============================== Review 1 ==============================\n",
      "\n",
      "ð¹ Original Review:\n",
      " Â I loved this product. But they only seem to last a few months. The company was great replacing the first one (the frother falls out of the handle and can't be fixed). The after 4 months my second one did the same. I only use the frother for coffee once a day. It's not overuse or abuse. I'm very disappointed and will look for another. As I understand they will only replace once. Anyway, if you have one good luck.\n",
      "\n",
      "ð¸ Translated Review:\n",
      " Critique : J'ai adorÃ© ce produit. Mais ils semblent seulement durer quelques mois. La compagnie a Ã©tÃ© gÃ©niale en remplaÃ§ant le premier (le fouet tombe du manche et ne peut Ãªtre rÃ©parÃ©). Mais aprÃ¨s 4 mois, mon deuxiÃ¨me a fait la mÃªme chose. Je n'utilise le fouet pour le cafÃ© qu'une fois par jour. Ce n'est pas de l'abus. Je suis trÃ¨s dÃ©Ã§u et vais chercher un autre produit. Ã ce que je comprends, ils ne le remplaceront qu'une seule fois. En tout cas, si vous en avez un, bonne chance.\n",
      "\n",
      "ð¸ Summary:\n",
      " The reviewer loved the product but found it only lasted a few months and had to be replaced twice.\n",
      "\n",
      "ð¸ Detected Language:\n",
      " English\n",
      "\n",
      "ð¸ Follow-up Message:\n",
      " Thank you for taking the time to write a review of our product. We are pleased to hear that you loved the product, but we are sorry to hear about the issues you experienced with its durability. We take all customer feedback seriously and will be looking into ways to improve the longevity of our products. Please reach out to our customer service team if you have any further concerns. Thank you for your support.\n",
      "\n",
      "============================== Review 2 ==============================\n",
      "\n",
      "ð¹ Original Review:\n",
      " This mattress had a small hole in the top of it (took forever to find where it was), and the patches that they provide did not work, maybe because it's the top of the mattress where it's kind of like fabric and a patch won't stick. Maybe I got unlucky with a defective mattress, but where's quality assurance for this company? That flat out should not happen. Emphasis on flat. Cause that's what the mattress was. Seriously horrible experience, ruined my friend's stay with me. Then they make you ship it back instead of just providing a refund, which is also super annoying to pack up an air mattress and take it to the UPS store. This company is the worst, and this mattress is the worst.\n",
      "\n",
      "ð¸ Translated Review:\n",
      " Avis : Ce matelas avait un petit trou sur le dessus (a pris une Ã©ternitÃ© pour le trouver), et les patchs fournis ne fonctionnaient pas, peut-Ãªtre parce que c'est le dessus du matelas oÃ¹ c'est un peu comme du tissu et un patch ne collera pas. Peut-Ãªtre que j'ai eu de la malchance avec un matelas dÃ©fectueux, mais oÃ¹ est l'assurance qualitÃ© pour cette entreprise ? Ãa ne devrait tout simplement pas arriver. Insistance sur le plat. Parce que c'est ce que le matelas Ã©tait. ExpÃ©rience vraiment horrible, a gÃ¢chÃ© le sÃ©jour de mon ami avec moi. Ensuite, ils vous obligent Ã  le renvoyer au lieu de simplement vous rembourser, ce qui est Ã©galement super ennuyeux de devoir emballer un matelas pneumatique et de l'emmener au magasin UPS. Cette entreprise est la pire, et ce matelas est le pire.\n",
      "\n",
      "ð¸ Summary:\n",
      " Overall negative review of a mattress with a small hole that was difficult to patch and ruined the reviewer's friend's stay, highlighting poor quality control and inconvenient return process.\n",
      "\n",
      "ð¸ Detected Language:\n",
      " English\n",
      "\n",
      "ð¸ Follow-up Message:\n",
      " Dear valued customer,\n",
      "\n",
      "We are truly sorry to hear about your negative experience with our mattress. We apologize for the inconvenience and frustration caused by the small hole and the difficulties you faced in trying to patch it.\n",
      "\n",
      "Quality control is of utmost importance to us and we are disappointed to hear that we fell short in providing you with a mattress that met our standards. Your feedback has been shared with our team to address this issue and prevent it from happening in the future.\n",
      "\n",
      "We understand the inconvenience of the return process and we are working to make it more seamless for our customers. We appreciate your patience and understanding as we strive to improve our services.\n",
      "\n",
      "Please know that your satisfaction is important to us and we would like the opportunity to make things right. If you have any further concerns or if there is anything else we can do to assist you, please do not hesitate to reach out to us.\n",
      "\n",
      "Thank you for bringing this to our attention and for giving us the opportunity to improve.\n",
      "\n",
      "Sincerely,\n",
      "[Your Company Name]\n"
     ]
    }
   ],
   "source": [
    "# Get two reviews from the DataFrame\n",
    "review1 = df.Review[4]\n",
    "review2 = df.Review[2]\n",
    "\n",
    "# Apply the overall_chain on the first review\n",
    "result1 = overall_chain({\"review\": review1})\n",
    "\n",
    "# Apply the overall_chain on the second review\n",
    "result2 = overall_chain({\"review\": review2})\n",
    "\n",
    "# Print results for Review 1\n",
    "print(\"=\"*30 + \" Review 1 \" + \"=\"*30)\n",
    "print(\"\\nð¹ Original Review:\\n\", review1)  \n",
    "print(\"\\nð¸ Translated Review:\\n\", result1[\"translated_review\"]) \n",
    "print(\"\\nð¸ Summary:\\n\", result1[\"summary\"]) \n",
    "print(\"\\nð¸ Detected Language:\\n\", result1[\"language\"])  \n",
    "print(\"\\nð¸ Follow-up Message:\\n\", result1[\"follow_up_message\"])  \n",
    "\n",
    "# Print results for Review 2\n",
    "print(\"\\n\" + \"=\"*30 + \" Review 2 \" + \"=\"*30)\n",
    "print(\"\\nð¹ Original Review:\\n\", review2)  \n",
    "print(\"\\nð¸ Translated Review:\\n\", result2[\"translated_review\"])  \n",
    "print(\"\\nð¸ Summary:\\n\", result2[\"summary\"])  \n",
    "print(\"\\nð¸ Detected Language:\\n\", result2[\"language\"])  #\n",
    "print(\"\\nð¸ Follow-up Message:\\n\", result2[\"follow_up_message\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"You are an excellent biologist. \\\n",
    "You have a deep understanding of living organisms, \\\n",
    "from the molecular and cellular level to entire ecosystems. \\\n",
    "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
    "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
    "You can clearly communicate how life functions and adapts, \\\n",
    "and you make connections between different biological concepts \\\n",
    "to answer challenging questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\",\n",
    "        \"description\": \"Good for answering biology questions\",\n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This radiation is characterized by a continuous spectrum of wavelengths and intensities, with the peak intensity shifting to shorter wavelengths as the temperature of the black body increases. Black body radiation plays a key role in understanding concepts such as thermal radiation and the behavior of objects at high temperatures.\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2 + 2 equals 4.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the proteins that make up our cells and tissues. \\n\\nHaving DNA in every cell ensures that each cell has the necessary information to carry out its specific functions and to replicate itself accurately during cell division. This ensures that the genetic information is passed on to the next generation of cells. \\n\\nAdditionally, DNA is constantly being used by cells to carry out processes such as protein synthesis, cell division, and repair. Having DNA in every cell allows for the coordination of these processes and ensures that the organism functions properly as a whole. \\n\\nIn summary, every cell in our body contains DNA because it is essential for the proper functioning and development of all living organisms.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "02e297da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Why do black holes emit Hawking radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " Response 1:\n",
      " Black holes emit Hawking radiation due to a quantum mechanical effect known as virtual particle pairs. According to quantum field theory, empty space is not truly empty but is filled with virtual particle-antiparticle pairs that constantly pop in and out of existence. \n",
      "\n",
      "When these pairs are created near the event horizon of a black hole, one particle may fall into the black hole while the other escapes into space. The particle that falls into the black hole has negative energy, causing the black hole to lose a small amount of mass. This loss of mass results in the emission of Hawking radiation.\n",
      "\n",
      "Hawking radiation is a form of thermal radiation that causes black holes to slowly lose mass and eventually evaporate over time. This phenomenon was first predicted by physicist Stephen Hawking in 1974 and has since been supported by experimental evidence.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "history: {'input': 'Explain the causes of the French Revolution.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " Response 2:\n",
      " The French Revolution was a complex and multifaceted event that was caused by a combination of social, political, and economic factors. Some of the key causes of the French Revolution include:\n",
      "\n",
      "1. Social Inequality: The French society was divided into three estates, with the clergy and nobility enjoying privileges and exemptions from taxes, while the common people, or the Third Estate, bore the burden of heavy taxation and had limited political rights. This social inequality created resentment and discontent among the lower classes.\n",
      "\n",
      "2. Economic Hardship: France was facing a financial crisis due to years of extravagant spending by the monarchy, costly wars, and a regressive tax system that placed the burden on the poor. The economic hardship faced by the common people exacerbated their discontent and fueled revolutionary sentiments.\n",
      "\n",
      "3. Enlightenment Ideas: The Enlightenment, a philosophical movement that emphasized reason, individual rights, and the rejection of traditional authority, had a significant impact on the intellectual climate in France. Enlightenment ideas inspired many French people to question the legitimacy of the monarchy and demand political reform.\n",
      "\n",
      "4. Political Corruption: The French monarchy was seen as corrupt and out of touch with the needs of the people. The absolute power of the king and the lack of political representation for the common people led to widespread dissatisfaction with the existing political system.\n",
      "\n",
      "5. Influence of the American Revolution: The success of the American Revolution in overthrowing colonial rule and establishing a democratic government inspired many French revolutionaries to seek similar political change in France.\n",
      "\n",
      "These factors, among others, contributed to the growing discontent and revolutionary fervor that ultimately led to the outbreak of the French Revolution in 1789.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'How do I implement a binary search in Python?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " Response 3:\n",
      " Here is a simple implementation of binary search in Python:\n",
      "\n",
      "```python\n",
      "def binary_search(arr, target):\n",
      "    low = 0\n",
      "    high = len(arr) - 1\n",
      "\n",
      "    while low <= high:\n",
      "        mid = (low + high) // 2\n",
      "        if arr[mid] == target:\n",
      "            return mid\n",
      "        elif arr[mid] < target:\n",
      "            low = mid + 1\n",
      "        else:\n",
      "            high = mid - 1\n",
      "\n",
      "    return -1\n",
      "\n",
      "# Example usage\n",
      "arr = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "target = 5\n",
      "result = binary_search(arr, target)\n",
      "if result != -1:\n",
      "    print(f\"Element found at index {result}\")\n",
      "else:\n",
      "    print(\"Element not found\")\n",
      "```\n",
      "\n",
      "In this implementation, we start by setting the low and high pointers to the beginning and end of the array, respectively. We then repeatedly calculate the middle index and compare the element at that index with the target value. If the element matches the target, we return the index. If the element is less than the target, we update the low pointer to mid + 1. If the element is greater than the target, we update the high pointer to mid - 1. We continue this process until the low pointer is greater than the high pointer, indicating that the target is not in the array.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain, MultiPromptChain\n",
    "from langchain.chains.router import LLMRouterChain\n",
    "\n",
    "\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model, select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if needed to improve the response.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object like:\n",
    "```json\n",
    "{{{{\n",
    "  \"destination\": string \\ \"name of the prompt\",\n",
    "  \"next_inputs\": string \\ \"modified input or the original\"\n",
    "}}}}\n",
    "'''\n",
    "<< CANDIDATE PROMPTS >> \n",
    "{destinations}\n",
    "\n",
    "<< INPUT >> \n",
    "{{input}} \n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n",
    "\n",
    "#Prepare router prompt\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str) \n",
    "router_prompt = PromptTemplate( template=router_template, input_variables=[\"input\"], output_parser=RouterOutputParser() )\n",
    "\n",
    "#Build the router chain\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt)\n",
    "\n",
    "#Default fallback prompt if no category matches\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\") \n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "\n",
    "#Final multi-prompt routing chain\n",
    "multi_chain = MultiPromptChain( router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True )\n",
    "\n",
    "response1 = multi_chain.run(\"Why do black holes emit Hawking radiation?\") \n",
    "print(\"\\n Response 1:\\n\", response1)\n",
    "response2 = multi_chain.run(\"Explain the causes of the French Revolution.\") \n",
    "print(\"\\n Response 2:\\n\", response2)\n",
    "\n",
    "response3 = multi_chain.run(\"How do I implement a binary search in Python?\") \n",
    "print(\"\\n Response 3:\\n\", response3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
